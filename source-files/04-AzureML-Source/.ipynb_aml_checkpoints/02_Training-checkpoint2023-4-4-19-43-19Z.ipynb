{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Training\r\n",
        "\r\n",
        "In this notebook, we will learn how to train an AI model in the cloud.  \r\n",
        "There are a few things that are special regarding Cloud AI training, but also a lot of similarities between our old-school way of working."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Again let us start by setting some global parameters first"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "INITIAL_LEARNING_RATE = 0.01\r\n",
        "MAX_EPOCHS = 50\r\n",
        "BATCH_SIZE = 32\r\n",
        "PATIENCE = 11\r\n",
        "model_name = 'animal-cnn'"
      ],
      "outputs": [],
      "execution_count": 26,
      "metadata": {
        "gather": {
          "logged": 1666099139834
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "And of course importing the packages we need! Again, don't forget to set your kernel right in the top-right corner!"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import cv2\r\n",
        "\r\n",
        "import os\r\n",
        "from glob import glob\r\n",
        "import warnings\r\n",
        "\r\n",
        "warnings.filterwarnings(\"ignore\")\r\n",
        "import random\r\n",
        "SEED = 42   # set random seed\r\n",
        "random.seed(SEED)\r\n",
        "\r\n",
        "from typing import List"
      ],
      "outputs": [],
      "execution_count": 27,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666099140465
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Import AzureML packages\r\n",
        "from azureml.core import Workspace\r\n",
        "from azureml.core import Dataset\r\n",
        "from azureml.data.datapath import DataPath\r\n",
        "from azureml.core.compute import AmlCompute\r\n",
        "from azureml.core.compute import ComputeTarget"
      ],
      "outputs": [],
      "execution_count": 28,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666099140961
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One special import are these Utils scripts. You can read more about them in the `utils > utils.py` file. I have included them here to load them in. They contain some helper functions we will be needing later on."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from utils.utils import *"
      ],
      "outputs": [],
      "execution_count": 29,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666099166204
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 1: Connect Workspace"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Follow the same steps as the previous notebook, to set up your Workspace configuration!"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Either get environment variables, or a fallback name, which is the second parameter.\r\n",
        "## Currently, fill in the fallback values. Later on, we will make sure to work with Environment values. So we're already preparing for it in here!\r\n",
        "workspace_name = os.environ.get('WORKSPACE', 'segers-nathan-ml')\r\n",
        "subscription_id = os.environ.get('SUBSCRIPTION_ID', 'ab96131e-f225-4b1f-95a9-12169fd4362e')\r\n",
        "resource_group = os.environ.get('RESOURCE_GROUP', '04_AzureML')"
      ],
      "outputs": [],
      "execution_count": 30,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666099166369
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ws = Workspace.get(name=workspace_name,\r\n",
        "               subscription_id=subscription_id,\r\n",
        "               resource_group=resource_group)"
      ],
      "outputs": [],
      "execution_count": 31,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666099166949
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 1.1 -- Create Compute Cluster\r\n",
        "\r\n",
        "A Compute Cluster is a combination of multiple Compute Instances. Azure will scale these machines according to the number of nodes we fill into the configuration.  \r\n",
        "Based on the amount of Jobs we want to run in parallel, multiple machines will be created.\r\n",
        "\r\n",
        "We choose to define a minimum of 0 machines, which means Azure will need some time to create at least one machine everytime we need one.\r\n",
        "If you keep the minimum on 1, you always have one that's ready for your development.\r\n",
        "The timeout time to scale down back to 0 machines can also be configured if required."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\r\n",
        "\r\n",
        "# choose a name for your cluster\r\n",
        "compute_name = os.environ.get(\"AML_COMPUTE_CLUSTER_NAME\", \"cpu-cluster\")\r\n",
        "compute_min_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MIN_NODES\", 0)\r\n",
        "compute_max_nodes = os.environ.get(\"AML_COMPUTE_CLUSTER_MAX_NODES\", 4)\r\n",
        "\r\n",
        "# This example uses CPU VM. For using GPU VM, set SKU to STANDARD_NC6\r\n",
        "vm_size = os.environ.get(\"AML_COMPUTE_CLUSTER_SKU\", \"STANDARD_D2_V2\")\r\n",
        "\r\n",
        "\r\n",
        "if compute_name in ws.compute_targets:\r\n",
        "    compute_target = ws.compute_targets[compute_name]\r\n",
        "    if compute_target and type(compute_target) is AmlCompute:\r\n",
        "        print(\"found compute target: \" + compute_name)\r\n",
        "else:\r\n",
        "    print(\"creating new compute target...\")\r\n",
        "    provisioning_config = AmlCompute.provisioning_configuration(vm_size = vm_size,\r\n",
        "                                                                min_nodes = compute_min_nodes, \r\n",
        "                                                                max_nodes = compute_max_nodes)\r\n",
        "\r\n",
        "    # create the cluster\r\n",
        "    compute_target = ComputeTarget.create(ws, compute_name, provisioning_config)\r\n",
        "    \r\n",
        "    # can poll for a minimum number of nodes and for a specific timeout. \r\n",
        "    # if no min node count is provided it will use the scale settings for the cluster\r\n",
        "    compute_target.wait_for_completion(show_output=True, min_node_count=None, timeout_in_minutes=20)\r\n",
        "    \r\n",
        "     # For a more detailed view of current AmlCompute status, use get_status()\r\n",
        "    print(compute_target.get_status().serialize())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "found compute target: cpu-cluster\n"
        }
      ],
      "execution_count": 32,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666099167795
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Find and download datasets"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "datasets = Dataset.get_all(workspace=ws) # Make sure to give our workspace with it\r\n",
        "print(datasets)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "{ 'animals-testing-set': DatasetRegistration(id='c9613e8b-2d88-4d1b-ae41-e9e0c287333d', name='animals-testing-set', version=1, description='The Animal Images to test, resized tot 64, 64', tags={'animals': 'cats_v1,dogs_v1,pandas_v1', 'AI-Model': 'CNN', 'Split size': '0.2', 'type': 'testing'}),\n  'animals-training-set': DatasetRegistration(id='d67473bf-834b-4515-8aa6-1aa7a2c028e3', name='animals-training-set', version=1, description='The Animal Images to train, resized tot 64, 64', tags={'animals': 'cats_v1,dogs_v1,pandas_v1', 'AI-Model': 'CNN', 'Split size': '0.8', 'type': 'training'}),\n  'cats_v1': DatasetRegistration(id='60e922db-b910-45af-8d8c-7c16ca84ac6d', name='cats_v1', version=1, description='', tags={}),\n  'dogs_v1': DatasetRegistration(id='0f30e7b1-4e97-493a-b5c8-7ae25743dbff', name='dogs_v1', version=1, description='', tags={}),\n  'pandas_v1': DatasetRegistration(id='56be96d0-8fea-439e-871e-55d06c4b7b31', name='pandas_v1', version=1, description='', tags={}),\n  'resized_cats_v1': DatasetRegistration(id='bc2b36c4-6029-4714-bb59-ee9cf85b047e', name='resized_cats_v1', version=1, description='cats_v1 images resized tot 64, 64', tags={'animals': 'cats_v1', 'AI-Model': 'CNN'}),\n  'resized_dogs_v1': DatasetRegistration(id='056c5a4f-59b4-4f6d-8302-5e68055631aa', name='resized_dogs_v1', version=1, description='dogs_v1 images resized tot 64, 64', tags={'animals': 'dogs_v1', 'AI-Model': 'CNN'}),\n  'resized_pandas_v1': DatasetRegistration(id='9819e12b-4ed2-4f20-a30d-4e07f4150537', name='resized_pandas_v1', version=1, description='pandas_v1 images resized tot 64, 64', tags={'animals': 'pandas_v1', 'AI-Model': 'CNN'})}\n"
        }
      ],
      "execution_count": 33,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666099168008
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Step 2: Create an AI model and training code\r\n",
        "\r\n",
        "We will first create an AI model to use in our training script.  \r\n",
        "A basic AI model has been given in the /utils/utils.py directory. You can change it there if you want to\r\n",
        "\r\n",
        "In this step, we will also configure a Training script. This script is an Executable Python script.  \r\n",
        "This is slightly different from our other way of working, where we work with Notebooks.\r\n",
        "\r\n",
        "Because Azure will be launching and running our Python scripts, we need to create one file that can be executed in one go.\r\n",
        "This needs all our imports, packages, data ... ready without manual interference."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll store all of these files into a scripts directory. That way we can upload that directory to our training VM later."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2.1 -- Prepare the scripts"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "script_folder = os.path.join(os.getcwd(), 'scripts')\r\n",
        "os.makedirs(script_folder, exist_ok=True)"
      ],
      "outputs": [],
      "execution_count": 34,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666099168136
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile $script_folder/train.py\r\n",
        "\r\n",
        "import argparse\r\n",
        "import os\r\n",
        "from glob import glob\r\n",
        "import random\r\n",
        "\r\n",
        "# This time we will need our Tensorflow Keras libraries, as we will be working with the AI training now\r\n",
        "from tensorflow import keras\r\n",
        "from tensorflow.keras.optimizers import SGD\r\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\r\n",
        "from sklearn.metrics import classification_report, confusion_matrix\r\n",
        "\r\n",
        "# This AzureML package will allow to log our metrics etc.\r\n",
        "from azureml.core import Run\r\n",
        "\r\n",
        "# Important to load in the utils as well!\r\n",
        "from utils import *\r\n",
        "\r\n",
        "\r\n",
        "### HARDCODED VARIABLES FOR NOW\r\n",
        "### TODO for the students:\r\n",
        "### Make sure to adapt the ArgumentParser on line 31 to include these parameters\r\n",
        "### You can base your answer on the lines that are already there\r\n",
        "\r\n",
        "SEED = 42\r\n",
        "INITIAL_LEARNING_RATE = 0.01\r\n",
        "BATCH_SIZE = 32\r\n",
        "PATIENCE = 11\r\n",
        "model_name = 'animal-cnn-test'\r\n",
        "\r\n",
        "\r\n",
        "parser = argparse.ArgumentParser()\r\n",
        "parser.add_argument('--training-folder', type=str, dest='training_folder', help='training folder mounting point')\r\n",
        "parser.add_argument('--testing-folder', type=str, dest='testing_folder', help='testing folder mounting point')\r\n",
        "parser.add_argument('--epochs', type=int, dest='epochs', help='The amount of Epochs to train')\r\n",
        "args = parser.parse_args()\r\n",
        "\r\n",
        "\r\n",
        "training_folder = args.training_folder\r\n",
        "print('Training folder:', training_folder)\r\n",
        "\r\n",
        "testing_folder = args.testing_folder\r\n",
        "print('Testing folder:', testing_folder)\r\n",
        "\r\n",
        "MAX_EPOCHS = args.epochs\r\n",
        "\r\n",
        "# As we're mounting the training_folder and testing_folder onto the `/mnt/data` directories, we can load in the images by using glob.\r\n",
        "training_paths = glob(os.path.join('/mnt/data/train', '**', 'processed_animals', '**', '*.jpg'), recursive=True)\r\n",
        "testing_paths = glob(os.path.join('/mnt/data/test', '**', 'processed_animals', '**', '*.jpg'), recursive=True)\r\n",
        "\r\n",
        "print(\"Training samples:\", len(training_paths))\r\n",
        "print(\"Testing samples:\", len(testing_paths))\r\n",
        "\r\n",
        "# Make sure to shuffle in the same way as I'm doing everything\r\n",
        "random.seed(SEED)\r\n",
        "random.shuffle(training_paths)\r\n",
        "random.seed(SEED)\r\n",
        "random.shuffle(testing_paths)\r\n",
        "\r\n",
        "print(training_paths[:3]) # Examples\r\n",
        "print(testing_paths[:3]) # Examples\r\n",
        "\r\n",
        "# Parse to Features and Targets for both Training and Testing. Refer to the Utils package for more information\r\n",
        "X_train = getFeatures(training_paths)\r\n",
        "y_train = getTargets(training_paths)\r\n",
        "\r\n",
        "X_test = getFeatures(testing_paths)\r\n",
        "y_test = getTargets(testing_paths)\r\n",
        "\r\n",
        "print('Shapes:')\r\n",
        "print(X_train.shape)\r\n",
        "print(X_test.shape)\r\n",
        "print(len(y_train))\r\n",
        "print(len(y_test))\r\n",
        "\r\n",
        "# Make sure the data is one-hot-encoded\r\n",
        "LABELS, y_train, y_test = encodeLabels(y_train, y_test)\r\n",
        "print('One Hot Shapes:')\r\n",
        "\r\n",
        "print(y_train.shape)\r\n",
        "print(y_test.shape)\r\n",
        "\r\n",
        "# Create an output directory where our AI model will be saved to.\r\n",
        "# Everything inside the `outputs` directory will be logged and kept aside for later usage.\r\n",
        "model_path = os.path.join('outputs', model_name)\r\n",
        "os.makedirs(model_path, exist_ok=True)\r\n",
        "\r\n",
        "## START OUR RUN context.\r\n",
        "## We can now log interesting information to Azure, by using these methods.\r\n",
        "run = Run.get_context()\r\n",
        "\r\n",
        "# Save the best model, not the last\r\n",
        "cb_save_best_model = keras.callbacks.ModelCheckpoint(filepath=model_path,\r\n",
        "                                                         monitor='val_loss', \r\n",
        "                                                         save_best_only=True, \r\n",
        "                                                         verbose=1)\r\n",
        "\r\n",
        "# Early stop when the val_los isn't improving for PATIENCE epochs\r\n",
        "cb_early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', \r\n",
        "                                              patience= PATIENCE,\r\n",
        "                                              verbose=1,\r\n",
        "                                              restore_best_weights=True)\r\n",
        "\r\n",
        "# Reduce the Learning Rate when not learning more for 4 epochs.\r\n",
        "cb_reduce_lr_on_plateau = keras.callbacks.ReduceLROnPlateau(factor=.5, patience=4, verbose=1)\r\n",
        "\r\n",
        "opt = SGD(lr=INITIAL_LEARNING_RATE, decay=INITIAL_LEARNING_RATE / MAX_EPOCHS) # Define the Optimizer\r\n",
        "\r\n",
        "model = buildModel((64, 64, 3), 3) # Create the AI model as defined in the utils script.\r\n",
        "\r\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\r\n",
        "\r\n",
        "# Construct & initialize the image data generator for data augmentation\r\n",
        "# Image augmentation allows us to construct “additional” training data from our existing training data \r\n",
        "# by randomly rotating, shifting, shearing, zooming, and flipping. This is to avoid overfitting.\r\n",
        "# It also allows us to fit AI models using a Generator, so we don't need to capture the whole dataset in memory at once.\r\n",
        "aug = ImageDataGenerator(rotation_range=30, width_shift_range=0.1,\r\n",
        "                         height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,\r\n",
        "                         horizontal_flip=True, fill_mode=\"nearest\")\r\n",
        "\r\n",
        "\r\n",
        "# train the network\r\n",
        "history = model.fit( aug.flow(X_train, y_train, batch_size=BATCH_SIZE),\r\n",
        "                        validation_data=(X_test, y_test),\r\n",
        "                        steps_per_epoch=len(X_train) // BATCH_SIZE,\r\n",
        "                        epochs=MAX_EPOCHS,\r\n",
        "                        callbacks=[cb_save_best_model, cb_early_stop, cb_reduce_lr_on_plateau] )\r\n",
        "\r\n",
        "print(\"[INFO] evaluating network...\")\r\n",
        "predictions = model.predict(X_test, batch_size=32)\r\n",
        "print(classification_report(y_test.argmax(axis=1), predictions.argmax(axis=1), target_names=['cats', 'dogs', 'panda'])) # Give the target names to easier refer to them.\r\n",
        "# If you want, you can enter the target names as a parameter as well, in case you ever adapt your AI model to more animals.\r\n",
        "\r\n",
        "cf_matrix = confusion_matrix(y_test.argmax(axis=1), predictions.argmax(axis=1))\r\n",
        "print(cf_matrix)\r\n",
        "\r\n",
        "### TODO for students\r\n",
        "### Find a way to log more information to the Run context.\r\n",
        "\r\n",
        "# Save the confusion matrix to the outputs.\r\n",
        "np.save('outputs/confusion_matrix.npy', cf_matrix)\r\n",
        "\r\n",
        "print(\"DONE TRAINING\")\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Overwriting /mnt/batch/tasks/shared/LS_root/mounts/clusters/compute-nathan/code/Users/nathan.segers/scripts/train.py\n"
        }
      ],
      "execution_count": 35,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy the Utils file into the script_folder\r\n",
        "import shutil\r\n",
        "shutil.copy('utils/utils.py', script_folder)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 36,
          "data": {
            "text/plain": "'/mnt/batch/tasks/shared/LS_root/mounts/clusters/compute-nathan/code/Users/nathan.segers/scripts/utils.py'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 36,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666099168462
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2.2 -- Prepare the environment\r\n",
        "\r\n",
        "The training script we have just defined still needs some more information before we can start it.  \r\n",
        "We'll need to define it's Anaconda or Pip environment with all the packages that should be installed prior to training.  \r\n",
        "We can re-use the environments later, or we can use environments other people have created for us.\r\n",
        "\r\n",
        "You can also customize the Base Docker image to train on, if you prefer. I won't use this in here."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.environment import Environment\r\n",
        "from azureml.core.conda_dependencies import CondaDependencies\r\n",
        "\r\n",
        "# Create an Environment name for later use\r\n",
        "environment_name = os.environ.get('TRAINING_ENV_NAME', 'animals-classification-env-training')\r\n",
        "env = Environment(environment_name)\r\n",
        "\r\n",
        "# It's called CondaDependencies, but you can also use pip packages ;-)\r\n",
        "env.python.conda_dependencies = CondaDependencies.create(\r\n",
        "        # Using opencv-python-headless is interesting to skip the overhead of packages that we don't need in a headless-VM.\r\n",
        "        pip_packages=['azureml-dataset-runtime[pandas,fuse]', 'azureml-defaults', 'tensorflow', 'scikit-learn', 'opencv-python-headless']\r\n",
        "    )\r\n",
        "# Register environment to re-use later\r\n",
        "env.register(workspace = ws)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 37,
          "data": {
            "text/plain": "{\n    \"assetId\": \"azureml://locations/westeurope/workspaces/69e8c700-8fe9-4ad8-8b8e-f7024a56791d/environments/animals-classification-env-training/versions/1\",\n    \"databricks\": {\n        \"eggLibraries\": [],\n        \"jarLibraries\": [],\n        \"mavenLibraries\": [],\n        \"pypiLibraries\": [],\n        \"rcranLibraries\": []\n    },\n    \"docker\": {\n        \"arguments\": [],\n        \"baseDockerfile\": null,\n        \"baseImage\": \"mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20220708.v1\",\n        \"baseImageRegistry\": {\n            \"address\": null,\n            \"password\": null,\n            \"registryIdentity\": null,\n            \"username\": null\n        },\n        \"buildContext\": null,\n        \"enabled\": false,\n        \"platform\": {\n            \"architecture\": \"amd64\",\n            \"os\": \"Linux\"\n        },\n        \"sharedVolumes\": true,\n        \"shmSize\": null\n    },\n    \"environmentVariables\": {\n        \"EXAMPLE_ENV_VAR\": \"EXAMPLE_VALUE\"\n    },\n    \"inferencingStackVersion\": null,\n    \"name\": \"animals-classification-env-training\",\n    \"python\": {\n        \"baseCondaEnvironment\": null,\n        \"condaDependencies\": {\n            \"channels\": [\n                \"anaconda\",\n                \"conda-forge\"\n            ],\n            \"dependencies\": [\n                \"python=3.8.13\",\n                {\n                    \"pip\": [\n                        \"azureml-dataset-runtime[pandas,fuse]~=1.44.0\",\n                        \"azureml-defaults~=1.44.0\",\n                        \"tensorflow\",\n                        \"scikit-learn\",\n                        \"opencv-python-headless\"\n                    ]\n                }\n            ],\n            \"name\": \"project_environment\"\n        },\n        \"condaDependenciesFile\": null,\n        \"interpreterPath\": \"python\",\n        \"userManagedDependencies\": false\n    },\n    \"r\": null,\n    \"spark\": {\n        \"packages\": [],\n        \"precachePackages\": true,\n        \"repositories\": []\n    },\n    \"version\": \"1\"\n}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 37,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666099173435
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2.3 -- Prepare the ScriptRunConfig\r\n",
        "\r\n",
        "A **ScriptRunConfig** is a configuration that contains all the information needed to launch a Job inside an Experiment.\r\n",
        "This contains information to the directory of scripts it should use, the **name** of the script to start,\r\n",
        "the **arguments** to pass into that script, the **compute** target to run the script on, and finally the **environment** to run it on.\r\n",
        "\r\n",
        "We then need to attach such a ScriptRunConfig onto an Experiment on Azure."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import ScriptRunConfig\r\n",
        "from azureml.core import Experiment\r\n",
        "\r\n",
        "experiment_name = os.environ.get('EXPERIMENT_NAME', 'Animals-Classification')\r\n",
        "\r\n",
        "exp = Experiment(workspace=ws, name=experiment_name) # Create a new experiment\r\n",
        "\r\n",
        "experiment_runs = []\r\n",
        "\r\n",
        "# We can start four experiments for a bunch of different epoch options\r\n",
        "for epochs in [25, 50, 75, 100]:\r\n",
        "    args = [\r\n",
        "        '--training-folder', datasets['animals-training-set'].as_mount('/mnt/data/train'),\r\n",
        "        '--testing-folder', datasets['animals-testing-set'].as_mount('/mnt/data/test'),\r\n",
        "        '--epochs', epochs]\r\n",
        "\r\n",
        "    script_run_config = ScriptRunConfig(\r\n",
        "                      source_directory=script_folder,\r\n",
        "                      script='train.py', \r\n",
        "                      arguments=args,\r\n",
        "                      compute_target=compute_target,\r\n",
        "                      environment=env)\r\n",
        "\r\n",
        "    run = exp.submit(config=script_run_config)\r\n",
        "    experiment_runs.append(run) # Append it to our list of experiment runs for now. This is easy for referring later!\r\n",
        "    print('Run started!')\r\n",
        "\r\n",
        "    "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Run started!\nRun started!\nRun started!\nRun started!\n"
        }
      ],
      "execution_count": 38,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666099185184
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2.4 -- Await the results!\r\n",
        "\r\n",
        "Now that our experiment runs are starting, we can await the logs and results.  \r\n",
        "It can take a while to run everything, but the 4 jobs should run in Parallel, if all was well configured!\r\n",
        "\r\n",
        "The cells below can help you in viewing the results, while you head out for a coffee!\r\n",
        "\r\n",
        "I use the `experiment_runs[0]` as our run to log. It's the first one that was started.\r\n",
        "\r\n",
        "There are a few different options for each to select the one they prefer :-)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 2.4.1 -- Plain text output"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# specify show_output to True for a verbose log\r\n",
        "experiment_runs[0].wait_for_completion(show_output=True) "
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "RunId: Animals-Classification_1665671672_bb3f4fbf\nWeb View: https://ml.azure.com/runs/Animals-Classification_1665671672_bb3f4fbf?wsid=/subscriptions/ab96131e-f225-4b1f-95a9-12169fd4362e/resourcegroups/04_AzureML/workspaces/segers-nathan-ml&tid=4ded4bb1-6bff-42b3-aed7-6a36a503bf7a\n\nStreaming azureml-logs/20_image_build_log.txt\n=============================================\n\n2022/10/13 14:34:39 Downloading source code...\n2022/10/13 14:34:40 Finished downloading source code\n2022/10/13 14:34:40 Creating Docker network: acb_default_network, driver: 'bridge'\n2022/10/13 14:34:41 Successfully set up Docker network: acb_default_network\n2022/10/13 14:34:41 Setting up Docker configuration...\n2022/10/13 14:34:41 Successfully set up Docker configuration\n2022/10/13 14:34:41 Logging in to registry: segersnathanacr.azurecr.io\n2022/10/13 14:34:42 Successfully logged into segersnathanacr.azurecr.io\n2022/10/13 14:34:42 Executing step ID: acb_step_0. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n2022/10/13 14:34:42 Scanning for dependencies...\n2022/10/13 14:34:42 Successfully scanned dependencies\n2022/10/13 14:34:42 Launching container with name: acb_step_0\nSending build context to Docker daemon  66.56kB\n\nStep 1/21 : FROM mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20220708.v1@sha256:2a7a3804e0b071870e78304aa13dab15c2ece3120f781a99d52f24ff6b71dea6\nmcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20220708.v1@sha256:2a7a3804e0b071870e78304aa13dab15c2ece3120f781a99d52f24ff6b71dea6: Pulling from azureml/openmpi4.1.0-ubuntu20.04\nd7bfe07ed847: Already exists\n1a9a51b4af0d: Pulling fs layer\n9d74d44c539e: Pulling fs layer\n829bf1798a9e: Pulling fs layer\n5fe57cb5a06b: Pulling fs layer\n0b73c9d3e4c7: Pulling fs layer\ndf3a1ae83fc1: Pulling fs layer\n622a938b5eec: Pulling fs layer\n9d0e20c4f643: Pulling fs layer\ne63d29d12ed0: Pulling fs layer\n5fe57cb5a06b: Waiting\n0b73c9d3e4c7: Waiting\ndf3a1ae83fc1: Waiting\n622a938b5eec: Waiting\n9d0e20c4f643: Waiting\ne63d29d12ed0: Waiting\n829bf1798a9e: Verifying Checksum\n829bf1798a9e: Download complete\n9d74d44c539e: Verifying Checksum\n9d74d44c539e: Download complete\n5fe57cb5a06b: Verifying Checksum\n5fe57cb5a06b: Download complete\ndf3a1ae83fc1: Verifying Checksum\ndf3a1ae83fc1: Download complete\n0b73c9d3e4c7: Verifying Checksum\n0b73c9d3e4c7: Download complete\n622a938b5eec: Verifying Checksum\n622a938b5eec: Download complete\ne63d29d12ed0: Verifying Checksum\ne63d29d12ed0: Download complete\n9d0e20c4f643: Verifying Checksum\n9d0e20c4f643: Download complete\n1a9a51b4af0d: Download complete\n1a9a51b4af0d: Pull complete\n9d74d44c539e: Pull complete\n829bf1798a9e: Pull complete\n5fe57cb5a06b: Pull complete\n0b73c9d3e4c7: Pull complete\ndf3a1ae83fc1: Pull complete\n622a938b5eec: Pull complete\n9d0e20c4f643: Pull complete\ne63d29d12ed0: Pull complete\nDigest: sha256:2a7a3804e0b071870e78304aa13dab15c2ece3120f781a99d52f24ff6b71dea6\nStatus: Downloaded newer image for mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20220708.v1@sha256:2a7a3804e0b071870e78304aa13dab15c2ece3120f781a99d52f24ff6b71dea6\n ---> a126cf3d80b0\nStep 2/21 : USER root\n ---> Running in 435bea87bef1\nRemoving intermediate container 435bea87bef1\n ---> 41bf3c394bc6\nStep 3/21 : RUN mkdir -p $HOME/.cache\n ---> Running in 71a2ae3d6159\nRemoving intermediate container 71a2ae3d6159\n ---> 273efe44f6fb\nStep 4/21 : WORKDIR /\n ---> Running in 30f57ee0b22c\nRemoving intermediate container 30f57ee0b22c\n ---> 93d555592041\nStep 5/21 : COPY azureml-environment-setup/99brokenproxy /etc/apt/apt.conf.d/\n ---> f15326cdeba2\nStep 6/21 : RUN if dpkg --compare-versions `conda --version | grep -oE '[^ ]+$'` lt 4.4.11; then conda install conda==4.4.11; fi\n ---> Running in ecdcf724b018\nRemoving intermediate container ecdcf724b018\n ---> 591acfea5ee6\nStep 7/21 : COPY azureml-environment-setup/mutated_conda_dependencies.yml azureml-environment-setup/mutated_conda_dependencies.yml\n ---> 6d766830e1fb\nStep 8/21 : RUN ldconfig /usr/local/cuda/lib64/stubs && conda env create -p /azureml-envs/azureml_228c4e08a949dcae1dc8d53fe3f82896 -f azureml-environment-setup/mutated_conda_dependencies.yml && rm -rf \"$HOME/.cache/pip\" && conda clean -aqy && CONDA_ROOT_DIR=$(conda info --root) && rm -rf \"$CONDA_ROOT_DIR/pkgs\" && find \"$CONDA_ROOT_DIR\" -type d -name __pycache__ -exec rm -rf {} + && ldconfig\n ---> Running in 1620700a3033\nWarning: you have pip-installed dependencies in your environment file, but you do not list pip itself as one of your conda dependencies.  Conda may not use the correct pip to install your packages, and they may end up in the wrong place.  Please add an explicit pip dependency.  I'm adding one for you, but still nagging you.\nCollecting package metadata (repodata.json): ...working... \ndone\nSolving environment: ...working... done\n\nDownloading and Extracting Packages\n\nreadline-8.1.2       | 423 KB    |            |   0% \nreadline-8.1.2       | 423 KB    | 3          |   4% \nreadline-8.1.2       | 423 KB    | ########## | 100% \n\npip-22.1.2           | 2.9 MB    |            |   0% \npip-22.1.2           | 2.9 MB    | ##2        |  23% \npip-22.1.2           | 2.9 MB    | ########## | 100% \npip-22.1.2           | 2.9 MB    | ########## | 100% \n\nca-certificates-2022 | 131 KB    |            |   0% \nca-certificates-2022 | 131 KB    | ########## | 100% \n\nzlib-1.2.12          | 130 KB    |            |   0% \nzlib-1.2.12          | 130 KB    | ########## | 100% \n\nlibgcc-ng-11.2.0     | 8.5 MB    |            |   0% \nlibgcc-ng-11.2.0     | 8.5 MB    | #######2   |  72% \nlibgcc-ng-11.2.0     | 8.5 MB    | ########## | 100% \n\nlibstdcxx-ng-11.2.0  | 6.1 MB    |            |   0% \nlibstdcxx-ng-11.2.0  | 6.1 MB    | ########## | 100% \nlibstdcxx-ng-11.2.0  | 6.1 MB    | ########## | 100% \n\nlibgomp-11.2.0       | 560 KB    |            |   0% \nlibgomp-11.2.0       | 560 KB    | ########## | 100% \nlibgomp-11.2.0       | 560 KB    | ########## | 100% \n\nxz-5.2.5             | 389 KB    |            |   0% \nxz-5.2.5             | 389 KB    | ########## | 100% \nxz-5.2.5             | 389 KB    | ########## | 100% \n\nlibffi-3.3           | 54 KB     |            |   0% \nlibffi-3.3           | 54 KB     | ########## | 100% \n\nopenssl-1.1.1q       | 3.8 MB    |            |   0% \nopenssl-1.1.1q       | 3.8 MB    | ########3  |  83% \nopenssl-1.1.1q       | 3.8 MB    | ########## | 100% \n\npython-3.8.13        | 22.7 MB   |            |   0% \npython-3.8.13        | 22.7 MB   | #3         |  14% \npython-3.8.13        | 22.7 MB   | #####6     |  56% \npython-3.8.13        | 22.7 MB   | #########2 |  93% \npython-3.8.13        | 22.7 MB   | ########## | 100% \n\n_openmp_mutex-5.1    | 20 KB     |            |   0% \n_openmp_mutex-5.1    | 20 KB     | ########## | 100% \n\ncertifi-2022.6.15    | 156 KB    |            |   0% \ncertifi-2022.6.15    | 156 KB    | ########## | 100% \n\ntk-8.6.12            | 3.3 MB    |            |   0% \ntk-8.6.12            | 3.3 MB    | #########5 |  95% \ntk-8.6.12            | 3.3 MB    | ########## | 100% \n\nsqlite-3.39.2        | 1.5 MB    |            |   0% \nsqlite-3.39.2        | 1.5 MB    | ########## | 100% \nsqlite-3.39.2        | 1.5 MB    | ########## | 100% \n\nsetuptools-61.2.0    | 1.3 MB    |            |   0% \nsetuptools-61.2.0    | 1.3 MB    | ########## | 100% \nsetuptools-61.2.0    | 1.3 MB    | ########## | 100% \n\nncurses-6.3          | 1.1 MB    |            |   0% \nncurses-6.3          | 1.1 MB    | ########## | 100% \nncurses-6.3          | 1.1 MB    | ########## | 100% \n\n_libgcc_mutex-0.1    | 3 KB      |            |   0% \n_libgcc_mutex-0.1    | 3 KB      | ########## | 100% \n\nld_impl_linux-64-2.3 | 732 KB    |            |   0% \nld_impl_linux-64-2.3 | 732 KB    | ########## | 100% \nld_impl_linux-64-2.3 | 732 KB    | ########## | 100% \n\nwheel-0.37.1         | 31 KB     |            |   0% \nwheel-0.37.1         | 31 KB     | ########## | 100% \nPreparing transaction: ...working... done\nVerifying transaction: ...working... done\nExecuting transaction: ...working... done\nInstalling pip dependencies: ...working... \nRan pip subprocess with arguments:\n['/azureml-envs/azureml_228c4e08a949dcae1dc8d53fe3f82896/bin/python', '-m', 'pip', 'install', '-U', '-r', '/azureml-environment-setup/condaenv.twp96jdf.requirements.txt']\nPip subprocess output:\nCollecting azureml-dataset-runtime[fuse,pandas]~=1.44.0\n  Downloading azureml_dataset_runtime-1.44.0-py3-none-any.whl (2.3 kB)\nCollecting azureml-defaults~=1.44.0\n  Downloading azureml_defaults-1.44.0-py3-none-any.whl (2.0 kB)\nCollecting tensorflow\n  Downloading tensorflow-2.10.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.1 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 578.1/578.1 MB 5.8 MB/s eta 0:00:00\nCollecting scikit-learn\n  Downloading scikit_learn-1.1.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31.2 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 31.2/31.2 MB 67.4 MB/s eta 0:00:00\nCollecting opencv-python-headless\n  Downloading opencv_python_headless-4.6.0.66-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (48.3 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 48.3/48.3 MB 62.0 MB/s eta 0:00:00\nCollecting numpy!=1.19.3\n  Downloading numpy-1.23.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 17.1/17.1 MB 102.0 MB/s eta 0:00:00\nCollecting azureml-dataprep<4.3.0a,>=4.2.0a\n  Downloading azureml_dataprep-4.2.2-py3-none-any.whl (43.4 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 43.4/43.4 MB 44.3 MB/s eta 0:00:00\nCollecting pyarrow<6.0.1,>=0.17.0\n  Downloading pyarrow-6.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25.6 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 25.6/25.6 MB 73.2 MB/s eta 0:00:00\nCollecting fusepy<4.0.0,>=3.0.1\n  Downloading fusepy-3.0.1.tar.gz (11 kB)\n  Preparing metadata (setup.py): started\n  Preparing metadata (setup.py): finished with status 'done'\nCollecting pandas<2.0.0,>=0.23.4\n  Downloading pandas-1.5.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.2 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 12.2/12.2 MB 89.8 MB/s eta 0:00:00\nCollecting configparser==3.7.4\n  Downloading configparser-3.7.4-py2.py3-none-any.whl (22 kB)\nCollecting json-logging-py==0.2\n  Downloading json-logging-py-0.2.tar.gz (3.6 kB)\n  Preparing metadata (setup.py): started\n  Preparing metadata (setup.py): finished with status 'done'\nCollecting azureml-inference-server-http~=0.7.2\n  Downloading azureml_inference_server_http-0.7.6-py3-none-any.whl (56 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 56.7/56.7 kB 10.1 MB/s eta 0:00:00\nCollecting azureml-core~=1.44.0\n  Downloading azureml_core-1.44.0-py3-none-any.whl (2.7 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.7/2.7 MB 100.8 MB/s eta 0:00:00\nCollecting gast<=0.4.0,>=0.2.1\n  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\nCollecting packaging\n  Downloading packaging-21.3-py3-none-any.whl (40 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 40.8/40.8 kB 7.7 MB/s eta 0:00:00\nCollecting termcolor>=1.1.0\n  Downloading termcolor-2.0.1-py3-none-any.whl (5.4 kB)\nCollecting grpcio<2.0,>=1.24.3\n  Downloading grpcio-1.49.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.7/4.7 MB 80.1 MB/s eta 0:00:00\nCollecting protobuf<3.20,>=3.9.2\n  Downloading protobuf-3.19.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 82.2 MB/s eta 0:00:00\nCollecting tensorboard<2.11,>=2.10\n  Downloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.9/5.9 MB 95.7 MB/s eta 0:00:00\nCollecting keras-preprocessing>=1.1.1\n  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 42.6/42.6 kB 7.9 MB/s eta 0:00:00\nCollecting wrapt>=1.11.0\n  Downloading wrapt-1.14.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (81 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 81.0/81.0 kB 16.5 MB/s eta 0:00:00\nCollecting google-pasta>=0.1.1\n  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 57.5/57.5 kB 10.6 MB/s eta 0:00:00\nCollecting typing-extensions>=3.6.6\n  Downloading typing_extensions-4.4.0-py3-none-any.whl (26 kB)\nCollecting tensorflow-io-gcs-filesystem>=0.23.1\n  Downloading tensorflow_io_gcs_filesystem-0.27.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.4/2.4 MB 92.3 MB/s eta 0:00:00\nCollecting keras<2.11,>=2.10.0\n  Downloading keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.7/1.7 MB 86.1 MB/s eta 0:00:00\nCollecting opt-einsum>=2.3.2\n  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 65.5/65.5 kB 16.3 MB/s eta 0:00:00\nCollecting libclang>=13.0.0\n  Downloading libclang-14.0.6-py2.py3-none-manylinux2010_x86_64.whl (14.1 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 14.1/14.1 MB 99.0 MB/s eta 0:00:00\nRequirement already satisfied: setuptools in /azureml-envs/azureml_228c4e08a949dcae1dc8d53fe3f82896/lib/python3.8/site-packages (from tensorflow->-r /azureml-environment-setup/condaenv.twp96jdf.requirements.txt (line 3)) (61.2.0)\nCollecting six>=1.12.0\n  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\nCollecting flatbuffers>=2.0\n  Downloading flatbuffers-22.9.24-py2.py3-none-any.whl (26 kB)\nCollecting tensorflow-estimator<2.11,>=2.10.0\n  Downloading tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 438.7/438.7 kB 64.4 MB/s eta 0:00:00\nCollecting astunparse>=1.6.0\n  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\nCollecting h5py>=2.9.0\n  Downloading h5py-3.7.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.5 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.5/4.5 MB 90.4 MB/s eta 0:00:00\nCollecting absl-py>=1.0.0\n  Downloading absl_py-1.2.0-py3-none-any.whl (123 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 123.4/123.4 kB 16.3 MB/s eta 0:00:00\nCollecting joblib>=1.0.0\n  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 298.0/298.0 kB 50.7 MB/s eta 0:00:00\nCollecting threadpoolctl>=2.0.0\n  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\nCollecting scipy>=1.3.2\n  Downloading scipy-1.9.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (33.8 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 33.8/33.8 MB 61.0 MB/s eta 0:00:00\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /azureml-envs/azureml_228c4e08a949dcae1dc8d53fe3f82896/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow->-r /azureml-environment-setup/condaenv.twp96jdf.requirements.txt (line 3)) (0.37.1)\nCollecting paramiko<3.0.0,>=2.0.8\n  Downloading paramiko-2.11.0-py2.py3-none-any.whl (212 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 212.9/212.9 kB 35.2 MB/s eta 0:00:00\nCollecting backports.tempfile\n  Downloading backports.tempfile-1.0-py2.py3-none-any.whl (4.4 kB)\nCollecting msal<2.0.0,>=1.15.0\n  Downloading msal-1.20.0-py2.py3-none-any.whl (90 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 90.0/90.0 kB 10.4 MB/s eta 0:00:00\nCollecting humanfriendly<11.0,>=4.7\n  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 86.8/86.8 kB 17.1 MB/s eta 0:00:00\nCollecting python-dateutil<3.0.0,>=2.7.3\n  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 247.7/247.7 kB 43.5 MB/s eta 0:00:00\nCollecting pytz\n  Downloading pytz-2022.4-py2.py3-none-any.whl (500 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 500.8/500.8 kB 51.5 MB/s eta 0:00:00\nCollecting azure-graphrbac<1.0.0,>=0.40.0\n  Downloading azure_graphrbac-0.61.1-py2.py3-none-any.whl (141 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 141.4/141.4 kB 24.3 MB/s eta 0:00:00\nCollecting ndg-httpsclient<=0.5.1\n  Downloading ndg_httpsclient-0.5.1-py3-none-any.whl (34 kB)\nCollecting msrest<=0.7.1,>=0.5.1\n  Downloading msrest-0.7.1-py3-none-any.whl (85 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 85.4/85.4 kB 16.7 MB/s eta 0:00:00\nCollecting msrestazure<=0.6.4,>=0.4.33\n  Downloading msrestazure-0.6.4-py2.py3-none-any.whl (40 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 40.5/40.5 kB 6.9 MB/s eta 0:00:00\nCollecting cryptography!=1.9,!=2.0.*,!=2.1.*,!=2.2.*,<38.0.0\n  Downloading cryptography-37.0.4-cp36-abi3-manylinux_2_24_x86_64.whl (4.1 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.1/4.1 MB 76.9 MB/s eta 0:00:00\nCollecting pyopenssl<23.0.0\n  Downloading pyOpenSSL-22.1.0-py3-none-any.whl (57 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 57.0/57.0 kB 8.7 MB/s eta 0:00:00\nCollecting jmespath<=1.0.0\n  Downloading jmespath-1.0.0-py3-none-any.whl (23 kB)\nCollecting SecretStorage<4.0.0\n  Downloading SecretStorage-3.3.3-py3-none-any.whl (15 kB)\nCollecting azure-common<2.0.0,>=1.1.12\n  Downloading azure_common-1.1.28-py2.py3-none-any.whl (14 kB)\nCollecting azure-mgmt-resource<22.0.0,>=15.0.0\n  Downloading azure_mgmt_resource-21.2.0-py3-none-any.whl (2.3 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.3/2.3 MB 64.8 MB/s eta 0:00:00\nCollecting azure-mgmt-storage<=20.0.0,>=16.0.0\n  Downloading azure_mgmt_storage-20.0.0-py3-none-any.whl (2.0 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.0/2.0 MB 79.3 MB/s eta 0:00:00\nCollecting requests[socks]<3.0.0,>=2.19.1\n  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 62.8/62.8 kB 14.0 MB/s eta 0:00:00\nCollecting urllib3<=1.26.9,>=1.23\n  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 139.0/139.0 kB 25.8 MB/s eta 0:00:00\nCollecting azure-mgmt-keyvault<11.0.0,>=0.40.0\n  Downloading azure_mgmt_keyvault-10.1.0-py3-none-any.whl (605 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 605.9/605.9 kB 49.7 MB/s eta 0:00:00\nCollecting azure-mgmt-containerregistry<11,>=8.2.0\n  Downloading azure_mgmt_containerregistry-10.0.0-py3-none-any.whl (1.2 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.2/1.2 MB 72.8 MB/s eta 0:00:00\nCollecting adal<=1.2.7,>=1.2.0\n  Downloading adal-1.2.7-py2.py3-none-any.whl (55 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 55.5/55.5 kB 12.2 MB/s eta 0:00:00\nCollecting docker<6.0.0\n  Downloading docker-5.0.3-py2.py3-none-any.whl (146 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 146.2/146.2 kB 26.5 MB/s eta 0:00:00\nCollecting PyJWT<3.0.0\n  Downloading PyJWT-2.5.0-py3-none-any.whl (20 kB)\nCollecting contextlib2<22.0.0\n  Downloading contextlib2-21.6.0-py2.py3-none-any.whl (13 kB)\nCollecting jsonpickle<3.0.0\n  Downloading jsonpickle-2.2.0-py2.py3-none-any.whl (39 kB)\nCollecting pkginfo\n  Downloading pkginfo-1.8.3-py2.py3-none-any.whl (26 kB)\nCollecting azure-mgmt-authorization<3,>=0.40.0\n  Downloading azure_mgmt_authorization-2.0.0-py2.py3-none-any.whl (465 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 465.2/465.2 kB 59.6 MB/s eta 0:00:00\nCollecting msal-extensions<=1.0.0,>=0.3.0\n  Downloading msal_extensions-1.0.0-py2.py3-none-any.whl (19 kB)\nCollecting pathspec<1.0.0\n  Downloading pathspec-0.10.1-py3-none-any.whl (27 kB)\nCollecting argcomplete<3\n  Downloading argcomplete-2.0.0-py2.py3-none-any.whl (37 kB)\nCollecting knack~=0.9.0\n  Downloading knack-0.9.0-py3-none-any.whl (59 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 59.8/59.8 kB 9.7 MB/s eta 0:00:00\nCollecting azure-core<2.0.0\n  Downloading azure_core-1.26.0-py3-none-any.whl (178 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 178.9/178.9 kB 12.3 MB/s eta 0:00:00\nCollecting dotnetcore2<4.0.0,>=3.0.0\n  Downloading dotnetcore2-3.1.23-py3-none-manylinux1_x86_64.whl (31.1 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 31.1/31.1 MB 76.1 MB/s eta 0:00:00\nCollecting azure-identity==1.7.0\n  Downloading azure_identity-1.7.0-py2.py3-none-any.whl (129 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 129.1/129.1 kB 25.6 MB/s eta 0:00:00\nCollecting pyyaml<7.0.0,>=5.1.0\n  Downloading PyYAML-6.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (701 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 701.2/701.2 kB 68.8 MB/s eta 0:00:00\nCollecting azureml-dataprep-rslex~=2.8.0dev0\n  Downloading azureml_dataprep_rslex-2.8.1-cp38-cp38-manylinux2010_x86_64.whl (16.5 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 16.5/16.5 MB 95.2 MB/s eta 0:00:00\nCollecting cloudpickle<3.0.0,>=1.1.0\n  Downloading cloudpickle-2.2.0-py3-none-any.whl (25 kB)\nCollecting azureml-dataprep-native<39.0.0,>=38.0.0\n  Downloading azureml_dataprep_native-38.0.0-cp38-cp38-manylinux1_x86_64.whl (1.4 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.4/1.4 MB 83.6 MB/s eta 0:00:00\nCollecting jsonschema\n  Downloading jsonschema-4.16.0-py3-none-any.whl (83 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 83.1/83.1 kB 18.2 MB/s eta 0:00:00\nCollecting msal-extensions<=1.0.0,>=0.3.0\n  Downloading msal_extensions-0.3.1-py2.py3-none-any.whl (18 kB)\nCollecting flask<2.2.0\n  Downloading Flask-2.1.3-py3-none-any.whl (95 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 95.6/95.6 kB 23.2 MB/s eta 0:00:00\nCollecting inference-schema~=1.4.0\n  Downloading inference_schema-1.4.2.1-py3-none-any.whl (21 kB)\nCollecting gunicorn==20.1.0\n  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 79.5/79.5 kB 8.1 MB/s eta 0:00:00\nCollecting opencensus-ext-azure~=1.1.0\n  Downloading opencensus_ext_azure-1.1.7-py2.py3-none-any.whl (42 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 42.8/42.8 kB 9.2 MB/s eta 0:00:00\nCollecting flask-cors~=3.0.1\n  Downloading Flask_Cors-3.0.10-py2.py3-none-any.whl (14 kB)\nCollecting pyparsing!=3.0.5,>=2.0.2\n  Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 98.3/98.3 kB 20.6 MB/s eta 0:00:00\nCollecting werkzeug>=1.0.1\n  Downloading Werkzeug-2.2.2-py3-none-any.whl (232 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 232.7/232.7 kB 43.1 MB/s eta 0:00:00\nCollecting markdown>=2.6.8\n  Downloading Markdown-3.4.1-py3-none-any.whl (93 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 93.3/93.3 kB 18.7 MB/s eta 0:00:00\nCollecting tensorboard-data-server<0.7.0,>=0.6.0\n  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.9/4.9 MB 99.9 MB/s eta 0:00:00\nCollecting tensorboard-plugin-wit>=1.6.0\n  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 781.3/781.3 kB 79.5 MB/s eta 0:00:00\nCollecting google-auth<3,>=1.6.3\n  Downloading google_auth-2.12.0-py2.py3-none-any.whl (169 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 169.8/169.8 kB 29.1 MB/s eta 0:00:00\nCollecting google-auth-oauthlib<0.5,>=0.4.1\n  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\nCollecting azure-mgmt-core<2.0.0,>=1.2.0\n  Downloading azure_mgmt_core-1.3.2-py3-none-any.whl (26 kB)\nCollecting cffi>=1.12\n  Downloading cffi-1.15.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (442 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 442.7/442.7 kB 66.0 MB/s eta 0:00:00\nCollecting websocket-client>=0.32.0\n  Downloading websocket_client-1.4.1-py3-none-any.whl (55 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 55.0/55.0 kB 11.3 MB/s eta 0:00:00\nCollecting distro>=1.2.0\n  Downloading distro-1.8.0-py3-none-any.whl (20 kB)\nCollecting Jinja2>=3.0\n  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 133.1/133.1 kB 26.5 MB/s eta 0:00:00\nCollecting click>=8.0\n  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 96.6/96.6 kB 18.7 MB/s eta 0:00:00\nCollecting importlib-metadata>=3.6.0\n  Downloading importlib_metadata-5.0.0-py3-none-any.whl (21 kB)\nCollecting itsdangerous>=2.0\n  Downloading itsdangerous-2.1.2-py3-none-any.whl (15 kB)\nCollecting rsa<5,>=3.1.4\n  Downloading rsa-4.9-py3-none-any.whl (34 kB)\nCollecting pyasn1-modules>=0.2.1\n  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 155.3/155.3 kB 33.5 MB/s eta 0:00:00\nCollecting cachetools<6.0,>=2.0.0\n  Downloading cachetools-5.2.0-py3-none-any.whl (9.3 kB)\nCollecting requests-oauthlib>=0.7.0\n  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\nCollecting wrapt>=1.11.0\n  Downloading wrapt-1.12.1.tar.gz (27 kB)\n  Preparing metadata (setup.py): started\n  Preparing metadata (setup.py): finished with status 'done'\nCollecting pygments\n  Downloading Pygments-2.13.0-py3-none-any.whl (1.1 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 26.2 MB/s eta 0:00:00\nCollecting tabulate\n  Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\nCollecting portalocker<3,>=1.0\n  Downloading portalocker-2.5.1-py2.py3-none-any.whl (15 kB)\nRequirement already satisfied: certifi>=2017.4.17 in /azureml-envs/azureml_228c4e08a949dcae1dc8d53fe3f82896/lib/python3.8/site-packages (from msrest<=0.7.1,>=0.5.1->azureml-core~=1.44.0->azureml-defaults~=1.44.0->-r /azureml-environment-setup/condaenv.twp96jdf.requirements.txt (line 2)) (2022.6.15)\nCollecting isodate>=0.6.0\n  Downloading isodate-0.6.1-py2.py3-none-any.whl (41 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 41.7/41.7 kB 7.8 MB/s eta 0:00:00\nCollecting pyasn1>=0.1.1\n  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 77.1/77.1 kB 15.8 MB/s eta 0:00:00\nCollecting opencensus<1.0.0,>=0.11.0\n  Downloading opencensus-0.11.0-py2.py3-none-any.whl (128 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 128.2/128.2 kB 18.0 MB/s eta 0:00:00\nCollecting psutil>=5.6.3\n  Downloading psutil-5.9.2-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (284 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 284.8/284.8 kB 46.1 MB/s eta 0:00:00\nCollecting bcrypt>=3.1.3\n  Downloading bcrypt-4.0.1-cp36-abi3-manylinux_2_28_x86_64.whl (593 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 593.7/593.7 kB 76.2 MB/s eta 0:00:00\nCollecting pynacl>=1.0.1\n  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 856.7/856.7 kB 71.3 MB/s eta 0:00:00\nCollecting pyopenssl<23.0.0\n  Downloading pyOpenSSL-22.0.0-py2.py3-none-any.whl (55 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 55.8/55.8 kB 1.3 MB/s eta 0:00:00\nCollecting charset-normalizer<3,>=2\n  Downloading charset_normalizer-2.1.1-py3-none-any.whl (39 kB)\nCollecting idna<4,>=2.5\n  Downloading idna-3.4-py3-none-any.whl (61 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 61.5/61.5 kB 14.1 MB/s eta 0:00:00\nCollecting PySocks!=1.5.7,>=1.5.6\n  Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\nCollecting jeepney>=0.6\n  Downloading jeepney-0.8.0-py3-none-any.whl (48 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 48.4/48.4 kB 1.6 MB/s eta 0:00:00\nCollecting MarkupSafe>=2.1.1\n  Downloading MarkupSafe-2.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\nCollecting backports.weakref\n  Downloading backports.weakref-1.0.post1-py2.py3-none-any.whl (5.2 kB)\nCollecting attrs>=17.4.0\n  Downloading attrs-22.1.0-py2.py3-none-any.whl (58 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 58.8/58.8 kB 1.9 MB/s eta 0:00:00\nCollecting pkgutil-resolve-name>=1.3.10\n  Downloading pkgutil_resolve_name-1.3.10-py3-none-any.whl (4.7 kB)\nCollecting pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0\n  Downloading pyrsistent-0.18.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (119 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 119.8/119.8 kB 27.2 MB/s eta 0:00:00\nCollecting importlib-resources>=1.4.0\n  Downloading importlib_resources-5.10.0-py3-none-any.whl (34 kB)\nCollecting pycparser\n  Downloading pycparser-2.21-py2.py3-none-any.whl (118 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 118.7/118.7 kB 23.5 MB/s eta 0:00:00\nCollecting zipp>=0.5\n  Downloading zipp-3.9.0-py3-none-any.whl (5.8 kB)\nCollecting opencensus-context>=0.1.3\n  Downloading opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\nCollecting google-api-core<3.0.0,>=1.0.0\n  Downloading google_api_core-2.10.2-py3-none-any.whl (115 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 115.6/115.6 kB 19.5 MB/s eta 0:00:00\nCollecting types-cryptography>=3.3.21\n  Downloading types_cryptography-3.3.23-py3-none-any.whl (30 kB)\nCollecting oauthlib>=3.0.0\n  Downloading oauthlib-3.2.1-py3-none-any.whl (151 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 151.7/151.7 kB 23.5 MB/s eta 0:00:00\nCollecting googleapis-common-protos<2.0dev,>=1.56.2\n  Downloading googleapis_common_protos-1.56.4-py2.py3-none-any.whl (211 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 211.7/211.7 kB 24.7 MB/s eta 0:00:00\nBuilding wheels for collected packages: json-logging-py, fusepy, wrapt\n  Building wheel for json-logging-py (setup.py): started\n  Building wheel for json-logging-py (setup.py): finished with status 'done'\n  Created wheel for json-logging-py: filename=json_logging_py-0.2-py3-none-any.whl size=3924 sha256=c8ea5600113637c5c180dbac7396c09c7ef57d3dbc99366c9d257067baa8f1e6\n  Stored in directory: /root/.cache/pip/wheels/e9/d6/70/7491901d808e74dd9238e4a91658ba108e4b5939b55327e6fb\n  Building wheel for fusepy (setup.py): started\n  Building wheel for fusepy (setup.py): finished with status 'done'\n  Created wheel for fusepy: filename=fusepy-3.0.1-py3-none-any.whl size=10503 sha256=83198321db213cc49a9bd5086ebe908d818b85e8f9d32093e9d9f3d009900d3b\n  Stored in directory: /root/.cache/pip/wheels/7f/41/10/f70b83a1164fdb95e7bc37bace13114a024227e56c2fee02bb\n  Building wheel for wrapt (setup.py): started\n  Building wheel for wrapt (setup.py): finished with status 'done'\n  Created wheel for wrapt: filename=wrapt-1.12.1-cp38-cp38-linux_x86_64.whl size=81713 sha256=09ec6adb316d3cd60d9f0de12f4a6358871626daa2d44d4d2c8ee728ffa12959\n  Stored in directory: /root/.cache/pip/wheels/5f/fd/9e/b6cf5890494cb8ef0b5eaff72e5d55a70fb56316007d6dfe73\nSuccessfully built json-logging-py fusepy wrapt\nInstalling collected packages: wrapt, types-cryptography, tensorboard-plugin-wit, pytz, pyasn1, opencensus-context, libclang, keras, json-logging-py, fusepy, flatbuffers, backports.weakref, azureml-dataprep-rslex, azureml-dataprep-native, azure-common, zipp, websocket-client, urllib3, typing-extensions, threadpoolctl, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, tabulate, six, rsa, pyyaml, PySocks, pyrsistent, pyparsing, PyJWT, pygments, pycparser, pyasn1-modules, psutil, protobuf, portalocker, pkgutil-resolve-name, pkginfo, pathspec, oauthlib, numpy, MarkupSafe, jsonpickle, joblib, jmespath, jeepney, itsdangerous, idna, humanfriendly, gunicorn, gast, distro, contextlib2, configparser, cloudpickle, click, charset-normalizer, cachetools, bcrypt, backports.tempfile, attrs, argcomplete, absl-py, werkzeug, scipy, requests, python-dateutil, pyarrow, packaging, opt-einsum, opencv-python-headless, knack, keras-preprocessing, Jinja2, isodate, importlib-resources, importlib-metadata, h5py, grpcio, googleapis-common-protos, google-pasta, google-auth, dotnetcore2, cffi, astunparse, scikit-learn, requests-oauthlib, pynacl, pandas, markdown, jsonschema, inference-schema, google-api-core, flask, docker, cryptography, azure-core, SecretStorage, pyopenssl, paramiko, opencensus, msrest, google-auth-oauthlib, flask-cors, azure-mgmt-core, adal, tensorboard, ndg-httpsclient, msrestazure, msal, azure-mgmt-storage, azure-mgmt-resource, azure-mgmt-keyvault, azure-mgmt-containerregistry, azure-mgmt-authorization, tensorflow, msal-extensions, azure-graphrbac, azureml-core, azure-identity, opencensus-ext-azure, azureml-dataprep, azureml-inference-server-http, azureml-dataset-runtime, azureml-defaults\nSuccessfully installed Jinja2-3.1.2 MarkupSafe-2.1.1 PyJWT-2.5.0 PySocks-1.7.1 SecretStorage-3.3.3 absl-py-1.2.0 adal-1.2.7 argcomplete-2.0.0 astunparse-1.6.3 attrs-22.1.0 azure-common-1.1.28 azure-core-1.26.0 azure-graphrbac-0.61.1 azure-identity-1.7.0 azure-mgmt-authorization-2.0.0 azure-mgmt-containerregistry-10.0.0 azure-mgmt-core-1.3.2 azure-mgmt-keyvault-10.1.0 azure-mgmt-resource-21.2.0 azure-mgmt-storage-20.0.0 azureml-core-1.44.0 azureml-dataprep-4.2.2 azureml-dataprep-native-38.0.0 azureml-dataprep-rslex-2.8.1 azureml-dataset-runtime-1.44.0 azureml-defaults-1.44.0 azureml-inference-server-http-0.7.6 backports.tempfile-1.0 backports.weakref-1.0.post1 bcrypt-4.0.1 cachetools-5.2.0 cffi-1.15.1 charset-normalizer-2.1.1 click-8.1.3 cloudpickle-2.2.0 configparser-3.7.4 contextlib2-21.6.0 cryptography-37.0.4 distro-1.8.0 docker-5.0.3 dotnetcore2-3.1.23 flask-2.1.3 flask-cors-3.0.10 flatbuffers-22.9.24 fusepy-3.0.1 gast-0.4.0 google-api-core-2.10.2 google-auth-2.12.0 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 googleapis-common-protos-1.56.4 grpcio-1.49.1 gunicorn-20.1.0 h5py-3.7.0 humanfriendly-10.0 idna-3.4 importlib-metadata-5.0.0 importlib-resources-5.10.0 inference-schema-1.4.2.1 isodate-0.6.1 itsdangerous-2.1.2 jeepney-0.8.0 jmespath-1.0.0 joblib-1.2.0 json-logging-py-0.2 jsonpickle-2.2.0 jsonschema-4.16.0 keras-2.10.0 keras-preprocessing-1.1.2 knack-0.9.0 libclang-14.0.6 markdown-3.4.1 msal-1.20.0 msal-extensions-0.3.1 msrest-0.7.1 msrestazure-0.6.4 ndg-httpsclient-0.5.1 numpy-1.23.4 oauthlib-3.2.1 opencensus-0.11.0 opencensus-context-0.1.3 opencensus-ext-azure-1.1.7 opencv-python-headless-4.6.0.66 opt-einsum-3.3.0 packaging-21.3 pandas-1.5.0 paramiko-2.11.0 pathspec-0.10.1 pkginfo-1.8.3 pkgutil-resolve-name-1.3.10 portalocker-2.5.1 protobuf-3.19.6 psutil-5.9.2 pyarrow-6.0.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 pycparser-2.21 pygments-2.13.0 pynacl-1.5.0 pyopenssl-22.0.0 pyparsing-3.0.9 pyrsistent-0.18.1 python-dateutil-2.8.2 pytz-2022.4 pyyaml-6.0 requests-2.28.1 requests-oauthlib-1.3.1 rsa-4.9 scikit-learn-1.1.2 scipy-1.9.2 six-1.16.0 tabulate-0.9.0 tensorboard-2.10.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.10.0 tensorflow-estimator-2.10.0 tensorflow-io-gcs-filesystem-0.27.0 termcolor-2.0.1 threadpoolctl-3.1.0 types-cryptography-3.3.23 typing-extensions-4.4.0 urllib3-1.26.9 websocket-client-1.4.1 werkzeug-2.2.2 wrapt-1.12.1 zipp-3.9.0\n\ndone\n\u001b[91m\n\n==> WARNING: A newer version of conda exists. <==\n  current version: 4.11.0\n  latest version: 22.9.0\n\nPlease update conda by running\n\n    $ conda update -n base -c defaults conda\n\n\n\u001b[0m#\n# To activate this environment, use\n#\n#     $ conda activate /azureml-envs/azureml_228c4e08a949dcae1dc8d53fe3f82896\n#\n# To deactivate an active environment, use\n#\n#     $ conda deactivate\n\nWARNING: /root/.conda/pkgs does not exist\nRemoving intermediate container 1620700a3033\n ---> cd370722dd67\nStep 9/21 : ENV PATH /azureml-envs/azureml_228c4e08a949dcae1dc8d53fe3f82896/bin:$PATH\n ---> Running in 327e1c9ccfca\nRemoving intermediate container 327e1c9ccfca\n ---> c536bfa9cf93\nStep 10/21 : COPY azureml-environment-setup/send_conda_dependencies.py azureml-environment-setup/send_conda_dependencies.py\n ---> 4f94e3339d67\nStep 11/21 : RUN echo \"Copying environment context\"\n ---> Running in b79e4cdad721\nCopying environment context\nRemoving intermediate container b79e4cdad721\n ---> dd30e7af4a4f\nStep 12/21 : COPY azureml-environment-setup/environment_context.json azureml-environment-setup/environment_context.json\n ---> 6aad398acda3\nStep 13/21 : RUN python /azureml-environment-setup/send_conda_dependencies.py -p /azureml-envs/azureml_228c4e08a949dcae1dc8d53fe3f82896\n ---> Running in d3ccdbdd4e3b\nReport materialized dependencies for the environment\nReading environment context\nExporting conda environment\nSending request with materialized conda environment details\nSuccessfully sent materialized environment details\nRemoving intermediate container d3ccdbdd4e3b\n ---> 9c60e2bfd008\nStep 14/21 : ENV AZUREML_CONDA_ENVIRONMENT_PATH /azureml-envs/azureml_228c4e08a949dcae1dc8d53fe3f82896\n ---> Running in 11c9038ea19b\nRemoving intermediate container 11c9038ea19b\n ---> 65f74dbdf141\nStep 15/21 : ENV LD_LIBRARY_PATH /azureml-envs/azureml_228c4e08a949dcae1dc8d53fe3f82896/lib:$LD_LIBRARY_PATH\n ---> Running in 768e9c86408d\nRemoving intermediate container 768e9c86408d\n ---> c6a966a8693f\nStep 16/21 : ENV CONDA_DEFAULT_ENV=azureml_228c4e08a949dcae1dc8d53fe3f82896 CONDA_PREFIX=/azureml-envs/azureml_228c4e08a949dcae1dc8d53fe3f82896\n ---> Running in 81edb6ac9849\nRemoving intermediate container 81edb6ac9849\n ---> 95abdaf3b61c\nStep 17/21 : COPY azureml-environment-setup/spark_cache.py azureml-environment-setup/log4j.properties /azureml-environment-setup/\n ---> cedc4e83e0b8\nStep 18/21 : RUN if [ $SPARK_HOME ]; then /bin/bash -c '$SPARK_HOME/bin/spark-submit  /azureml-environment-setup/spark_cache.py'; fi\n ---> Running in 7f01e14f3362\nRemoving intermediate container 7f01e14f3362\n ---> 47cd55df6255\nStep 19/21 : RUN rm -rf azureml-environment-setup\n ---> Running in 68db6e301585\nRemoving intermediate container 68db6e301585\n ---> 06db8dc26f60\nStep 20/21 : ENV AZUREML_ENVIRONMENT_IMAGE True\n ---> Running in 098ffc5b78c0\nRemoving intermediate container 098ffc5b78c0\n ---> 2b52ab8b971f\nStep 21/21 : CMD [\"bash\"]\n ---> Running in ff66014c3d16\nRemoving intermediate container ff66014c3d16\n ---> 444db75f709f\nSuccessfully built 444db75f709f\nSuccessfully tagged segersnathanacr.azurecr.io/azureml/azureml_06e397cce86d4564e5475c4870ab5419:latest\nSuccessfully tagged segersnathanacr.azurecr.io/azureml/azureml_06e397cce86d4564e5475c4870ab5419:1\n2022/10/13 14:38:41 Successfully executed container: acb_step_0\n2022/10/13 14:38:41 Executing step ID: acb_step_1. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n2022/10/13 14:38:41 Pushing image: segersnathanacr.azurecr.io/azureml/azureml_06e397cce86d4564e5475c4870ab5419:1, attempt 1\nThe push refers to repository [segersnathanacr.azurecr.io/azureml/azureml_06e397cce86d4564e5475c4870ab5419]\nc73bb1857863: Preparing\n20a269115474: Preparing\na3ba7fee73c9: Preparing\n1d94aee10c15: Preparing\nc4ce26fe0385: Preparing\n9ba5645bfe2c: Preparing\nec44511d3087: Preparing\n05e6762e8514: Preparing\nfc96633327e1: Preparing\nb8f2d4654def: Preparing\ncc45347b4ace: Preparing\n1b372d66233e: Preparing\n07a28cde7d10: Preparing\n30396212e2bd: Preparing\ne2efb02e0592: Preparing\ndafbdffeff20: Preparing\n657ccef222ea: Preparing\na2fbf4296693: Preparing\n149bb2b607d0: Preparing\naf7ed92504ae: Preparing\n9ba5645bfe2c: Waiting\nec44511d3087: Waiting\n05e6762e8514: Waiting\nfc96633327e1: Waiting\nb8f2d4654def: Waiting\ncc45347b4ace: Waiting\n1b372d66233e: Waiting\n07a28cde7d10: Waiting\n30396212e2bd: Waiting\ne2efb02e0592: Waiting\ndafbdffeff20: Waiting\n657ccef222ea: Waiting\na2fbf4296693: Waiting\n149bb2b607d0: Waiting\naf7ed92504ae: Waiting\nc4ce26fe0385: Pushed\nc73bb1857863: Pushed\n1d94aee10c15: Pushed\na3ba7fee73c9: Pushed\nec44511d3087: Pushed\n05e6762e8514: Pushed\nb8f2d4654def: Pushed\ncc45347b4ace: Pushed\n20a269115474: Pushed\n1b372d66233e: Pushed\nfc96633327e1: Pushed\ndafbdffeff20: Pushed\n07a28cde7d10: Pushed\n30396212e2bd: Pushed\n657ccef222ea: Pushed\na2fbf4296693: Pushed\ne2efb02e0592: Pushed\naf7ed92504ae: Pushed\n\n149bb2b607d0: Pushed\n9ba5645bfe2c: Pushed\n1: digest: sha256:aaade2de198e3df460150a0c5ad8ccfd05a9f7d08c24051221cf8571ecf1b0cd size: 4514\n2022/10/13 14:40:58 Successfully pushed image: segersnathanacr.azurecr.io/azureml/azureml_06e397cce86d4564e5475c4870ab5419:1\n2022/10/13 14:40:58 Executing step ID: acb_step_2. Timeout(sec): 5400, Working directory: '', Network: 'acb_default_network'\n2022/10/13 14:40:58 Pushing image: segersnathanacr.azurecr.io/azureml/azureml_06e397cce86d4564e5475c4870ab5419:latest, attempt 1\nThe push refers to repository [segersnathanacr.azurecr.io/azureml/azureml_06e397cce86d4564e5475c4870ab5419]\nc73bb1857863: Preparing\n20a269115474: Preparing\na3ba7fee73c9: Preparing\n1d94aee10c15: Preparing\nc4ce26fe0385: Preparing\n9ba5645bfe2c: Preparing\nec44511d3087: Preparing\n05e6762e8514: Preparing\nfc96633327e1: Preparing\nb8f2d4654def: Preparing\ncc45347b4ace: Preparing\n1b372d66233e: Preparing\n07a28cde7d10: Preparing\n30396212e2bd: Preparing\ne2efb02e0592: Preparing\ndafbdffeff20: Preparing\n657ccef222ea: Preparing\na2fbf4296693: Preparing\n149bb2b607d0: Preparing\naf7ed92504ae: Preparing\n9ba5645bfe2c: Waiting\nec44511d3087: Waiting\n05e6762e8514: Waiting\nfc96633327e1: Waiting\nb8f2d4654def: Waiting\ncc45347b4ace: Waiting\n1b372d66233e: Waiting\n07a28cde7d10: Waiting\n30396212e2bd: Waiting\ne2efb02e0592: Waiting\ndafbdffeff20: Waiting\n657ccef222ea: Waiting\na2fbf4296693: Waiting\n149bb2b607d0: Waiting\naf7ed92504ae: Waiting\n20a269115474: Layer already exists\nc4ce26fe0385: Layer already exists\na3ba7fee73c9: Layer already exists\nc73bb1857863: Layer already exists\n1d94aee10c15: Layer already exists\n9ba5645bfe2c: Layer already exists\nb8f2d4654def: Layer already exists\nec44511d3087: Layer already exists\n05e6762e8514: Layer already exists\ncc45347b4ace: Layer already exists\n1b372d66233e: Layer already exists\nfc96633327e1: Layer already exists\n07a28cde7d10: Layer already exists\n30396212e2bd: Layer already exists\ne2efb02e0592: Layer already exists\naf7ed92504ae: Layer already exists\na2fbf4296693: Layer already exists\n149bb2b607d0: Layer already exists\n657ccef222ea: Layer already exists\ndafbdffeff20: Layer already exists\nlatest: digest: sha256:aaade2de198e3df460150a0c5ad8ccfd05a9f7d08c24051221cf8571ecf1b0cd size: 4514\n2022/10/13 14:41:00 Successfully pushed image: segersnathanacr.azurecr.io/azureml/azureml_06e397cce86d4564e5475c4870ab5419:latest\n2022/10/13 14:41:00 Step ID: acb_step_0 marked as successful (elapsed time in seconds: 239.223219)\n2022/10/13 14:41:00 Populating digests for step ID: acb_step_0...\n2022/10/13 14:41:01 Successfully populated digests for step ID: acb_step_0\n2022/10/13 14:41:01 Step ID: acb_step_1 marked as successful (elapsed time in seconds: 136.917951)\n2022/10/13 14:41:01 Step ID: acb_step_2 marked as successful (elapsed time in seconds: 1.541815)\n2022/10/13 14:41:01 The following dependencies were found:\n2022/10/13 14:41:01 \n- image:\n    registry: segersnathanacr.azurecr.io\n    repository: azureml/azureml_06e397cce86d4564e5475c4870ab5419\n    tag: latest\n    digest: sha256:aaade2de198e3df460150a0c5ad8ccfd05a9f7d08c24051221cf8571ecf1b0cd\n  runtime-dependency:\n    registry: mcr.microsoft.com\n    repository: azureml/openmpi4.1.0-ubuntu20.04\n    tag: 20220708.v1\n    digest: sha256:2a7a3804e0b071870e78304aa13dab15c2ece3120f781a99d52f24ff6b71dea6\n  git: {}\n- image:\n    registry: segersnathanacr.azurecr.io\n    repository: azureml/azureml_06e397cce86d4564e5475c4870ab5419\n    tag: \"1\"\n    digest: sha256:aaade2de198e3df460150a0c5ad8ccfd05a9f7d08c24051221cf8571ecf1b0cd\n  runtime-dependency:\n    registry: mcr.microsoft.com\n    repository: azureml/openmpi4.1.0-ubuntu20.04\n    tag: 20220708.v1\n    digest: sha256:2a7a3804e0b071870e78304aa13dab15c2ece3120f781a99d52f24ff6b71dea6\n  git: {}\n\nRun ID: cb1 was successful after 6m23s\n"
        }
      ],
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 2.4.2 -- AzureML Widgets\r\n",
        "\r\n",
        "This needs an extra package to be installed, the AzureML widgets.\r\n",
        "(Change the environment if you're running this in a different Kernel)"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!/anaconda/envs/azureml_py38_tensorflow/bin/python -m pip install azureml-widgets"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.widgets import RunDetails\r\n",
        "RunDetails(experiment_runs[0]).show()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1640009944104
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Step 3 -- The Output!\r\n",
        "\r\n",
        "As a result of our experiments, we should have a trained AI model.  \r\n",
        "However, we have some more information that was logged or saved. You can find all this information in the Run context that we started, and Azure is filling in for us.\r\n",
        "\r\n",
        "Use the documentation to find out some more information.\r\n",
        "\r\n",
        "https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.scriptrun?view=azure-ml-py"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Experiment\r\n",
        "\r\n",
        "experiment_name = os.environ.get('EXPERIMENT_NAME', 'Animals-Classification')\r\n",
        "\r\n",
        "exp = Experiment(workspace=ws, name=experiment_name) # Re-use existing experiment with this name"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666094925091
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "exp"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": "Experiment(Name: Animals-Classification,\nWorkspace: segers-nathan-ml)",
            "text/html": "<table style=\"width:100%\"><tr><th>Name</th><th>Workspace</th><th>Report Page</th><th>Docs Page</th></tr><tr><td>Animals-Classification</td><td>segers-nathan-ml</td><td><a href=\"https://ml.azure.com/experiments/id/a72ed236-e8fc-4a7c-9c44-8083d938b0ee?wsid=/subscriptions/ab96131e-f225-4b1f-95a9-12169fd4362e/resourcegroups/04_AzureML/workspaces/segers-nathan-ml&amp;tid=4ded4bb1-6bff-42b3-aed7-6a36a503bf7a\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.experiment.Experiment?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 7,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666094938212
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "runs = exp.get_runs()"
      ],
      "outputs": [],
      "execution_count": 14,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666095045851
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "first_run = next(runs)\r\n",
        "second_run = next(runs)"
      ],
      "outputs": [],
      "execution_count": 15,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666095046348
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "third_run = next(runs)"
      ],
      "outputs": [],
      "execution_count": 24,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666095403560
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "first_run"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/plain": "Run(Experiment: Animals-Classification,\nId: Animals-Classification_1665671676_ff4b47ae,\nType: azureml.scriptrun,\nStatus: Completed)",
            "text/html": "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>Animals-Classification</td><td>Animals-Classification_1665671676_ff4b47ae</td><td>azureml.scriptrun</td><td>Completed</td><td><a href=\"https://ml.azure.com/runs/Animals-Classification_1665671676_ff4b47ae?wsid=/subscriptions/ab96131e-f225-4b1f-95a9-12169fd4362e/resourcegroups/04_AzureML/workspaces/segers-nathan-ml&amp;tid=4ded4bb1-6bff-42b3-aed7-6a36a503bf7a\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.run.Run?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 12,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666095021646
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "second_run.get_file_names()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 17,
          "data": {
            "text/plain": "['azureml-logs/20_image_build_log.txt',\n 'outputs/animal-cnn-test/keras_metadata.pb',\n 'outputs/animal-cnn-test/saved_model.pb',\n 'outputs/animal-cnn-test/variables/variables.data-00000-of-00001',\n 'outputs/animal-cnn-test/variables/variables.index',\n 'outputs/confusion_matrix.npy',\n 'system_logs/cs_capability/cs-capability.log',\n 'system_logs/data_capability/data-capability.log',\n 'system_logs/data_capability/rslex.log.2022-10-13-15',\n 'system_logs/hosttools_capability/hosttools-capability.log',\n 'system_logs/lifecycler/execution-wrapper.log',\n 'system_logs/lifecycler/lifecycler.log',\n 'system_logs/metrics_capability/metrics-capability.log',\n 'system_logs/snapshot_capability/snapshot-capability.log',\n 'user_logs/std_log.txt']"
          },
          "metadata": {}
        }
      ],
      "execution_count": 17,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666095081700
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# You can always save these details for further referencing!\r\n",
        "second_run.get_details()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 18,
          "data": {
            "text/plain": "{'runId': 'Animals-Classification_1665671675_fb2bceec',\n 'target': 'cpu-cluster',\n 'status': 'Completed',\n 'startTimeUtc': '2022-10-13T15:03:35.23391Z',\n 'endTimeUtc': '2022-10-13T15:24:11.958268Z',\n 'services': {},\n 'properties': {'_azureml.ComputeTargetType': 'amlctrain',\n  'ContentSnapshotId': '193c123e-84a6-43bb-a03b-bc2ce9ad1712',\n  'ProcessInfoFile': 'azureml-logs/process_info.json',\n  'ProcessStatusFile': 'azureml-logs/process_status.json'},\n 'inputDatasets': [{'dataset': {'id': 'd67473bf-834b-4515-8aa6-1aa7a2c028e3'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'input__d67473bf', 'mechanism': 'Mount', 'pathOnCompute': '/mnt/data/train'}}, {'dataset': {'id': 'c9613e8b-2d88-4d1b-ae41-e9e0c287333d'}, 'consumptionDetails': {'type': 'RunInput', 'inputName': 'input__c9613e8b', 'mechanism': 'Mount', 'pathOnCompute': '/mnt/data/test'}}],\n 'outputDatasets': [],\n 'runDefinition': {'script': 'train.py',\n  'command': '',\n  'useAbsolutePath': False,\n  'arguments': ['--training-folder',\n   'DatasetConsumptionConfig:input__d67473bf',\n   '--testing-folder',\n   'DatasetConsumptionConfig:input__c9613e8b',\n   '--epochs',\n   '50'],\n  'sourceDirectoryDataStore': None,\n  'framework': 'Python',\n  'communicator': 'None',\n  'target': 'cpu-cluster',\n  'dataReferences': {},\n  'data': {'input__d67473bf': {'dataLocation': {'dataset': {'id': 'd67473bf-834b-4515-8aa6-1aa7a2c028e3',\n      'name': 'animals-training-set',\n      'version': '1'},\n     'dataPath': None,\n     'uri': None,\n     'type': None},\n    'mechanism': 'Mount',\n    'environmentVariableName': 'input__d67473bf',\n    'pathOnCompute': '/mnt/data/train',\n    'overwrite': False,\n    'options': None},\n   'input__c9613e8b': {'dataLocation': {'dataset': {'id': 'c9613e8b-2d88-4d1b-ae41-e9e0c287333d',\n      'name': 'animals-testing-set',\n      'version': '1'},\n     'dataPath': None,\n     'uri': None,\n     'type': None},\n    'mechanism': 'Mount',\n    'environmentVariableName': 'input__c9613e8b',\n    'pathOnCompute': '/mnt/data/test',\n    'overwrite': False,\n    'options': None}},\n  'outputData': {},\n  'datacaches': [],\n  'jobName': None,\n  'maxRunDurationSeconds': 2592000,\n  'nodeCount': 1,\n  'instanceTypes': [],\n  'priority': None,\n  'credentialPassthrough': False,\n  'identity': None,\n  'environment': {'name': 'animals-classification-env-training',\n   'version': '1',\n   'assetId': 'azureml://locations/westeurope/workspaces/69e8c700-8fe9-4ad8-8b8e-f7024a56791d/environments/animals-classification-env-training/versions/1',\n   'autoRebuild': True,\n   'python': {'interpreterPath': 'python',\n    'userManagedDependencies': False,\n    'condaDependencies': {'name': 'project_environment',\n     'dependencies': ['python=3.8.13',\n      {'pip': ['azureml-dataset-runtime[pandas,fuse]~=1.44.0',\n        'azureml-defaults~=1.44.0',\n        'tensorflow',\n        'scikit-learn',\n        'opencv-python-headless']}],\n     'channels': ['anaconda', 'conda-forge']},\n    'baseCondaEnvironment': None},\n   'environmentVariables': {'EXAMPLE_ENV_VAR': 'EXAMPLE_VALUE'},\n   'docker': {'baseImage': 'mcr.microsoft.com/azureml/openmpi4.1.0-ubuntu20.04:20220708.v1',\n    'platform': {'os': 'Linux', 'architecture': 'amd64'},\n    'baseDockerfile': None,\n    'baseImageRegistry': {'address': None, 'username': None, 'password': None},\n    'enabled': False,\n    'arguments': []},\n   'spark': {'repositories': [], 'packages': [], 'precachePackages': True},\n   'inferencingStackVersion': None},\n  'history': {'outputCollection': True,\n   'directoriesToWatch': ['logs'],\n   'enableMLflowTracking': True,\n   'snapshotProject': True},\n  'spark': {'configuration': {'spark.app.name': 'Azure ML Experiment',\n    'spark.yarn.maxAppAttempts': '1'}},\n  'parallelTask': {'maxRetriesPerWorker': 0,\n   'workerCountPerNode': 1,\n   'terminalExitCodes': None,\n   'configuration': {}},\n  'amlCompute': {'name': None,\n   'vmSize': None,\n   'retainCluster': False,\n   'clusterMaxNodeCount': None},\n  'aiSuperComputer': {'instanceType': 'D2',\n   'imageVersion': 'pytorch-1.7.0',\n   'location': None,\n   'aiSuperComputerStorageData': None,\n   'interactive': False,\n   'scalePolicy': None,\n   'virtualClusterArmId': None,\n   'tensorboardLogDirectory': None,\n   'sshPublicKey': None,\n   'sshPublicKeys': None,\n   'enableAzmlInt': True,\n   'priority': 'Medium',\n   'slaTier': 'Standard',\n   'userAlias': None},\n  'kubernetesCompute': {'instanceType': None},\n  'tensorflow': {'workerCount': 1, 'parameterServerCount': 1},\n  'mpi': {'processCountPerNode': 1},\n  'pyTorch': {'communicationBackend': 'nccl', 'processCount': None},\n  'hdi': {'yarnDeployMode': 'Cluster'},\n  'containerInstance': {'region': None, 'cpuCores': 2.0, 'memoryGb': 3.5},\n  'exposedPorts': None,\n  'docker': {'useDocker': False,\n   'sharedVolumes': True,\n   'shmSize': '2g',\n   'arguments': []},\n  'cmk8sCompute': {'configuration': {}},\n  'commandReturnCodeConfig': {'returnCode': 'Zero',\n   'successfulReturnCodes': []},\n  'environmentVariables': {},\n  'applicationEndpoints': {},\n  'parameters': []},\n 'logFiles': {'azureml-logs/20_image_build_log.txt': 'https://segersnathanml6257146518.blob.core.windows.net/azureml/ExperimentRun/dcid.Animals-Classification_1665671675_fb2bceec/azureml-logs/20_image_build_log.txt?sv=2019-07-07&sr=b&sig=fSSoY%2FdK4LHRdI8ULr23HxD42S8aOdakoV1jfx8ZtjE%3D&skoid=11f39b22-876e-4dee-8c3a-d5149503484c&sktid=4ded4bb1-6bff-42b3-aed7-6a36a503bf7a&skt=2022-10-18T11%3A48%3A32Z&ske=2022-10-19T19%3A58%3A32Z&sks=b&skv=2019-07-07&st=2022-10-18T12%3A02%3A09Z&se=2022-10-18T20%3A12%3A09Z&sp=r',\n  'user_logs/std_log.txt': 'https://segersnathanml6257146518.blob.core.windows.net/azureml/ExperimentRun/dcid.Animals-Classification_1665671675_fb2bceec/user_logs/std_log.txt?sv=2019-07-07&sr=b&sig=ueBr5HIjfGDcRB5WOOrF92B5GYqhfyg1vVvnAg2Zmd4%3D&skoid=11f39b22-876e-4dee-8c3a-d5149503484c&sktid=4ded4bb1-6bff-42b3-aed7-6a36a503bf7a&skt=2022-10-18T11%3A48%3A32Z&ske=2022-10-19T19%3A58%3A32Z&sks=b&skv=2019-07-07&st=2022-10-18T12%3A02%3A09Z&se=2022-10-18T20%3A12%3A09Z&sp=r',\n  'system_logs/cs_capability/cs-capability.log': 'https://segersnathanml6257146518.blob.core.windows.net/azureml/ExperimentRun/dcid.Animals-Classification_1665671675_fb2bceec/system_logs/cs_capability/cs-capability.log?sv=2019-07-07&sr=b&sig=vLsSZrytU2%2FGE3KP2Zq9jzuCEl94k2oc0DR631RK40I%3D&skoid=11f39b22-876e-4dee-8c3a-d5149503484c&sktid=4ded4bb1-6bff-42b3-aed7-6a36a503bf7a&skt=2022-10-18T11%3A48%3A32Z&ske=2022-10-19T19%3A58%3A32Z&sks=b&skv=2019-07-07&st=2022-10-18T12%3A02%3A09Z&se=2022-10-18T20%3A12%3A09Z&sp=r',\n  'system_logs/data_capability/data-capability.log': 'https://segersnathanml6257146518.blob.core.windows.net/azureml/ExperimentRun/dcid.Animals-Classification_1665671675_fb2bceec/system_logs/data_capability/data-capability.log?sv=2019-07-07&sr=b&sig=bdvdqgmeqlghkF7PgyFssfje%2FdCZ6frx8bevi8BFhVU%3D&skoid=11f39b22-876e-4dee-8c3a-d5149503484c&sktid=4ded4bb1-6bff-42b3-aed7-6a36a503bf7a&skt=2022-10-18T11%3A48%3A32Z&ske=2022-10-19T19%3A58%3A32Z&sks=b&skv=2019-07-07&st=2022-10-18T12%3A02%3A09Z&se=2022-10-18T20%3A12%3A09Z&sp=r',\n  'system_logs/data_capability/rslex.log.2022-10-13-15': 'https://segersnathanml6257146518.blob.core.windows.net/azureml/ExperimentRun/dcid.Animals-Classification_1665671675_fb2bceec/system_logs/data_capability/rslex.log.2022-10-13-15?sv=2019-07-07&sr=b&sig=H9EngSJSVmbfTwXXt31xnHk6V%2FqbHl50%2FFWN8CnYB0s%3D&skoid=11f39b22-876e-4dee-8c3a-d5149503484c&sktid=4ded4bb1-6bff-42b3-aed7-6a36a503bf7a&skt=2022-10-18T11%3A48%3A32Z&ske=2022-10-19T19%3A58%3A32Z&sks=b&skv=2019-07-07&st=2022-10-18T12%3A02%3A09Z&se=2022-10-18T20%3A12%3A09Z&sp=r',\n  'system_logs/hosttools_capability/hosttools-capability.log': 'https://segersnathanml6257146518.blob.core.windows.net/azureml/ExperimentRun/dcid.Animals-Classification_1665671675_fb2bceec/system_logs/hosttools_capability/hosttools-capability.log?sv=2019-07-07&sr=b&sig=5gnkYcyYZxvpjlpTH%2B7ZPfy9F3D8KNLoH4uHFZdh18Y%3D&skoid=11f39b22-876e-4dee-8c3a-d5149503484c&sktid=4ded4bb1-6bff-42b3-aed7-6a36a503bf7a&skt=2022-10-18T11%3A48%3A32Z&ske=2022-10-19T19%3A58%3A32Z&sks=b&skv=2019-07-07&st=2022-10-18T12%3A02%3A09Z&se=2022-10-18T20%3A12%3A09Z&sp=r',\n  'system_logs/lifecycler/execution-wrapper.log': 'https://segersnathanml6257146518.blob.core.windows.net/azureml/ExperimentRun/dcid.Animals-Classification_1665671675_fb2bceec/system_logs/lifecycler/execution-wrapper.log?sv=2019-07-07&sr=b&sig=F1mFwQ8XNfYJK03pswYZV1PaiFnDoSSGdsLyLbG%2BZFg%3D&skoid=11f39b22-876e-4dee-8c3a-d5149503484c&sktid=4ded4bb1-6bff-42b3-aed7-6a36a503bf7a&skt=2022-10-18T11%3A48%3A32Z&ske=2022-10-19T19%3A58%3A32Z&sks=b&skv=2019-07-07&st=2022-10-18T12%3A02%3A09Z&se=2022-10-18T20%3A12%3A09Z&sp=r',\n  'system_logs/lifecycler/lifecycler.log': 'https://segersnathanml6257146518.blob.core.windows.net/azureml/ExperimentRun/dcid.Animals-Classification_1665671675_fb2bceec/system_logs/lifecycler/lifecycler.log?sv=2019-07-07&sr=b&sig=5jXOAynstnECOy72Q%2F%2FRG6yz6Krq1QWscCGjg5yyDMs%3D&skoid=11f39b22-876e-4dee-8c3a-d5149503484c&sktid=4ded4bb1-6bff-42b3-aed7-6a36a503bf7a&skt=2022-10-18T11%3A48%3A32Z&ske=2022-10-19T19%3A58%3A32Z&sks=b&skv=2019-07-07&st=2022-10-18T12%3A02%3A09Z&se=2022-10-18T20%3A12%3A09Z&sp=r',\n  'system_logs/metrics_capability/metrics-capability.log': 'https://segersnathanml6257146518.blob.core.windows.net/azureml/ExperimentRun/dcid.Animals-Classification_1665671675_fb2bceec/system_logs/metrics_capability/metrics-capability.log?sv=2019-07-07&sr=b&sig=kRLxpD6%2FqsY6wGP%2FWMcXG9rczWbgmv0Nv9KcQiWE0sU%3D&skoid=11f39b22-876e-4dee-8c3a-d5149503484c&sktid=4ded4bb1-6bff-42b3-aed7-6a36a503bf7a&skt=2022-10-18T11%3A48%3A32Z&ske=2022-10-19T19%3A58%3A32Z&sks=b&skv=2019-07-07&st=2022-10-18T12%3A02%3A09Z&se=2022-10-18T20%3A12%3A09Z&sp=r',\n  'system_logs/snapshot_capability/snapshot-capability.log': 'https://segersnathanml6257146518.blob.core.windows.net/azureml/ExperimentRun/dcid.Animals-Classification_1665671675_fb2bceec/system_logs/snapshot_capability/snapshot-capability.log?sv=2019-07-07&sr=b&sig=QsDRKZ7gy4T5o5%2FFN9AtbykUYlRK7xbmKKxDf9tH1xU%3D&skoid=11f39b22-876e-4dee-8c3a-d5149503484c&sktid=4ded4bb1-6bff-42b3-aed7-6a36a503bf7a&skt=2022-10-18T11%3A48%3A32Z&ske=2022-10-19T19%3A58%3A32Z&sks=b&skv=2019-07-07&st=2022-10-18T12%3A02%3A09Z&se=2022-10-18T20%3A12%3A09Z&sp=r'},\n 'submittedBy': 'Nathan Segers'}"
          },
          "metadata": {}
        }
      ],
      "execution_count": 18,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": true
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666095130591
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3.1 -- TODO: Finding the logs for a specific run based on it's ID.\r\n",
        "\r\n",
        "Try to create a function that find the logs for a specific run.  \r\n",
        "You only fill in the RunID number and you get the output you want."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# answer here"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1640007585777
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uncomment the cell below for a possible answer"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# %load code_solutions/ViewRunDetails.txt\n",
        "from azureml.core import Run\n",
        "test_run = Run(exp, 'Animals-Classification_1640006981_6a272b07')\n",
        "test_run.get_details()"
      ],
      "outputs": [],
      "execution_count": 19,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666095163164
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3.2 -- Registering and downloading our AI model\r\n",
        "\r\n",
        "In Azure Machine Learning Service, we can register AI models so that they are versioned and kept together with other AI models.  \r\n",
        "We keep track of their accuracy based on the runs they were created from.\r\n",
        "\r\n",
        "Just a few lines are needed to register and download the AI model."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = 'outputs/animal-cnn-test/'"
      ],
      "outputs": [],
      "execution_count": 20,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666095251635
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "second_run.download_files(prefix=model_path)"
      ],
      "outputs": [],
      "execution_count": 21,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666095266911
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "third_run.register_model(\r\n",
        "    model_name,\r\n",
        "    model_path=model_path,\r\n",
        "    tags={'animals': 'cats, dogs, pandas', 'AI-Model': 'CNN'},\r\n",
        "    description=\"Image classification on animals\",\r\n",
        "    sample_input_dataset=datasets['animals-testing-set']\r\n",
        ")"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 25,
          "data": {
            "text/plain": "Model(workspace=Workspace.create(name='segers-nathan-ml', subscription_id='ab96131e-f225-4b1f-95a9-12169fd4362e', resource_group='04_AzureML'), name=animal-cnn, id=animal-cnn:2, version=2, tags={'animals': 'cats, dogs, pandas', 'AI-Model': 'CNN'}, properties={})"
          },
          "metadata": {}
        }
      ],
      "execution_count": 25,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1666095411917
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python38-azureml-pt-tf",
      "language": "python",
      "display_name": "Python 3.8 - Pytorch and Tensorflow"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python38-azureml-pt-tf"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}